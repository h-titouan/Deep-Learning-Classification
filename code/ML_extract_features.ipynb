{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dépendances \n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Fonction de récupération des features dans une image\n",
    "def get_vector(image_name):\n",
    "\n",
    "    # Charger une image avec la librarie Pillow\n",
    "    img = Image.open(image_name)\n",
    "    # Créer une variable Pytorch afin de \n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    # Créer un vecteur de 0 qui contiendra les features \n",
    "    my_embedding = torch.zeros(512)\n",
    "    # Définir une fonction qui copy les résultats dans les couches\n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    # Lancer le modèle sur l'image \n",
    "    model(t_img)\n",
    "    h.remove()\n",
    "    # Renvoyer les features\n",
    "    return my_embedding.numpy()\n",
    "\n",
    "# Fonction qui boucle sur toutes les images d'un jeu de données\n",
    "def features_train(directory):\n",
    "\n",
    "    # On instancie les listes qui stockeront les informations\n",
    "    features = []\n",
    "    totaldir = []\n",
    "    y = []\n",
    "    \n",
    "    # Liste avec tous les chemins des images\n",
    "    damage_dir = str(directory + \"/damage/\")\n",
    "    damage = os.listdir(damage_dir)\n",
    "    for i in damage :\n",
    "        totaldir.append(str(damage_dir + i))\n",
    "        y.append(\"damage\")\n",
    "    \n",
    "    no_damage_dir = str(directory + \"/no_damage/\")\n",
    "    no_damage = os.listdir(no_damage_dir)\n",
    "    for i in no_damage :\n",
    "        totaldir.append(str(no_damage_dir + i))\n",
    "        y.append(\"no_damage\")\n",
    "\n",
    "    # Récupération des features dans les images\n",
    "    for dir in totaldir : \n",
    "        features.append(get_vector(dir))\n",
    "\n",
    "    features = pd.DataFrame(features)\n",
    "\n",
    "    return features, y\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluation(model, X_train, y_train, X_test, y_test, target_names):\n",
    "  model.fit(X_train, y_train)\n",
    "  ypred = model.predict(X_test)\n",
    "\n",
    "  print(pd.DataFrame(confusion_matrix(y_test,ypred), \n",
    "                  columns=['pred_0','pred_1'],\n",
    "                  index=['obs_0','obs_1']))\n",
    "                  \n",
    "\n",
    "  print(classification_report(y_test, ypred, target_names = target_names))\n",
    "\n",
    "# Fonction de Gridsearch\n",
    "def grid_search(model, parameters, scorer, cv, X_train, y_train):\n",
    "\n",
    "    best_model = GridSearchCV(model,param_grid = parameters, scoring = scorer, verbose = 2, cv = cv)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    return best_model.best_estimator_, best_model.scorer_, best_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin des différents datasets\n",
    "train = \"/Users/titouanhoude/Deep Learning/Post-hurricane/train_another\"\n",
    "validation = \"/Users/titouanhoude/Deep Learning/Post-hurricane/validation_another\"\n",
    "balanced_test = \"/Users/titouanhoude/Deep Learning/Post-hurricane/test\"\n",
    "unbalanced_test = \"/Users/titouanhoude/Deep Learning/Post-hurricane/test_another\"\n",
    "\n",
    "# Charger un modèle pré-entraîné\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Utiliser ce modèle pour obtenir la couche qui nous intérésse\n",
    "layer = model._modules.get('avgpool')\n",
    "\n",
    "# Evaluer ce modèle\n",
    "model.eval()\n",
    "\n",
    "# Transformer les images dans le bon format, normalisation et conversion en Tenseur\n",
    "scaler = transforms.Resize((150, 150))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "X_train, y_train = features_train(train)\n",
    "X_test, y_test = features_train(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pred_0  pred_1\n",
      "obs_0     942      58\n",
      "obs_1     124     876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      damage       0.88      0.94      0.91      1000\n",
      "   no_damage       0.94      0.88      0.91      1000\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.91      0.91      0.91      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Knn\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "target_names = [\"damage\", \"no_damage\"]\n",
    "\n",
    "evaluation(knn, X_train, y_train, X_test, y_test, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pred_0  pred_1\n",
      "obs_0     873     127\n",
      "obs_1      85     915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      damage       0.91      0.87      0.89      1000\n",
      "   no_damage       0.88      0.92      0.90      1000\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.89      0.89      0.89      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest de base\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "target_names = [\"damage\", \"no_damage\"]\n",
    "\n",
    "evaluation(clf, X_train, y_train, X_test, y_test, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de la Grid Search\n",
    "parameters = {'n_estimators' : np.arange(start = 10, stop = 210, step = 25), \n",
    "    'max_depth' : np.arange(start = 10, stop = 20, step = 2)}\n",
    "model = RandomForestClassifier()\n",
    "scorer = make_scorer(f1_score , average='macro')\n",
    "cv = 3\n",
    "\n",
    "# Grid Search du Random Forest\n",
    "best_estimator, best_scorer, best_score_ = grid_search(model, parameters, scorer, cv, X_train, y_train)\n",
    "\n",
    "print(\"Voici les paramètres du meilleure modèle : \" + str(best_estimator))\n",
    "print(\"Voici le \"  + str(best_scorer) + \" du meilleure modèle : \" + str(best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pred_0  pred_1\n",
      "obs_0     868     132\n",
      "obs_1      78     922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      damage       0.92      0.87      0.89      1000\n",
      "   no_damage       0.87      0.92      0.90      1000\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.90      0.90      0.89      2000\n",
      "weighted avg       0.90      0.90      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Random Forest avec les meilleurs paramètres\n",
    "clf = RandomForestClassifier(max_depth=16, n_estimators=110)\n",
    "target_names = [\"damage\", \"no_damage\"]\n",
    "\n",
    "evaluation(clf, X_train, y_train, X_test, y_test, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pred_0  pred_1\n",
      "obs_0     866     134\n",
      "obs_1      75     925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      damage       0.92      0.87      0.89      1000\n",
      "   no_damage       0.87      0.93      0.90      1000\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.90      0.90      0.90      2000\n",
      "weighted avg       0.90      0.90      0.90      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle XGB avec les meilleurs paramètres\n",
    "xgb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "target_names = [\"damage\", \"no_damage\"]\n",
    "\n",
    "evaluation(clf, X_train, y_train, X_test, y_test, target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
